{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of linebeam 3DXRD data from ID11\n",
    " This will do everything up to indexing grains\n",
    "* Create sparse representation of the data\n",
    "* Label the spots in the sparse data\n",
    "\n",
    "This code is largely based on notebooks written by Haixing Fang and Indrajeet Tambe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample='SiMo1000_6_v2'\n",
    "scan_names = ['05_0N_3DXRD']\n",
    "dataroot = '/Users/al8720/Library/CloudStorage/OneDrive-Malmöuniversitet/projects/castIron/ESRF22/analysis_23/tdxrd/linebeam/rawdata'\n",
    "analysisroot ='/Users/al8720/Library/CloudStorage/OneDrive-Malmöuniversitet/projects/castIron/ESRF22/analysis_23/tdxrd/linebeam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export an evironment variable related to SLURM\n",
    "%env SLURM_CPUS_PER_TASK=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fabio\n",
    "import ImageD11.sinograms.dataset\n",
    "import ImageD11.sinograms.properties\n",
    "import ImageD11.sinograms.lima_segmenter\n",
    "import ImageD11.sinograms.assemble_label\n",
    "import h5py, hdf5plugin\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "def setup_ds(scan_name, dataroot, analysisroot, sample,\n",
    "             detector='frelon3', omegamotor='diffrz', dtymotor='diffty'):\n",
    "    ds = ImageD11.sinograms.dataset.DataSet(dataroot,\n",
    "                                            analysisroot,\n",
    "                                            sample,\n",
    "                                            scan_name,\n",
    "                                            detector=detector,\n",
    "                                            omegamotor=omegamotor,\n",
    "                                            dtymotor=dtymotor)\n",
    "    ds.import_scans()\n",
    "    ds.import_imagefiles()\n",
    "    ds.import_motors_from_master()\n",
    "    print(ds)\n",
    "    outdir = os.path.join(ds.analysisroot,ds.sample)\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    print(outdir)\n",
    "    outname = f'ds_{scan_name}.h5'\n",
    "    ds.save(os.path.join(outdir,outname))\n",
    "    return ds, outname\n",
    "\n",
    "def make_bg(ds,detector='frelon3'):\n",
    "    imgs = [] #list of seleted frames from the scans\n",
    "    with h5py.File(os.path.join(ds.datapath,ds.masterfile),'r') as hin:\n",
    "        for scan in ds.scans:\n",
    "            nimg = hin[f'{scan}/measurement/{detector}'].shape[0] #nbr of images\n",
    "            for i in range(0,nimg,20): #take every 20th image for background estimation\n",
    "                imgs.append(hin[f'{scan}/measurement/{detector}'][i])\n",
    "    imgs=np.asarray(imgs)\n",
    "    #Go trough the image in steps of 5 5 times, find the min in each pixel. The backgroun is the mean of these\n",
    "    bg = np.mean([imgs[i::5].min(axis=0) for i in range(5)], axis=0)\n",
    "    if detector == 'frelon3':\n",
    "        mask = np.ones(bg.shape,bool) #this is a mask where noting is masked\n",
    "    else:\n",
    "        raise f'Mask not implemented for detector {detector}'\n",
    "    #save images\n",
    "    bkgim = os.path.join(ds.analysisroot,ds.sample,f'{ds.dset}_bkg.edf')\n",
    "    maskim = os.path.join(ds.analysisroot,ds.sample,f'{ds.dset}_{detector}_mask.edf')                 \n",
    "    fabio.edfimage.edfimage(bg.astype(np.float32)).write(bkgim)\n",
    "    fabio.edfimage.edfimage(mask.astype(np.uint8)).write(maskim)\n",
    "    frm = imgs[0]-bg #for checking segmentation\n",
    "    return bkgim, maskim, frm\n",
    "\n",
    "def segment_spots(ds, outname, bkgim, maskim, frm, \n",
    "                  cut_value=25, \n",
    "                  check_segmentation=True, \n",
    "                  run_all=False,\n",
    "                  parallel=True):\n",
    "    #write a slurm script for the segmenter\n",
    "    outdir = os.path.join(ds.analysisroot,ds.sample)\n",
    "    shscript = ImageD11.sinograms.lima_segmenter.setup(os.path.join(outdir,outname))\n",
    "\n",
    "    #set some segmenter options\n",
    "    with h5py.File(os.path.join(outdir,outname),'r+') as hin:\n",
    "        hin['lima_segmenter'].attrs['bgfile']=bkgim\n",
    "        hin['lima_segmenter'].attrs['maskfile']=maskim\n",
    "        hin['lima_segmenter'].attrs['cut']=cut_value\n",
    "    options = ImageD11.sinograms.lima_segmenter.SegmenterOptions()\n",
    "    options.load(os.path.join(outdir,outname),'lima_segmenter')\n",
    "    options.jobid = 0\n",
    "    mask = fabio.open(maskim).data\n",
    "    options.mask = mask\n",
    "    options.analysispath = os.path.join(outdir, f'{ds.sample}_{ds.dset}')\n",
    "    if not parallel:\n",
    "        options.files_per_core = len(ds.scans)\n",
    "    #save options as a global variable in the segmenter class\n",
    "    ImageD11.sinograms.lima_segmenter.OPTIONS = options\n",
    "    print(options)\n",
    "    if check_segmentation:\n",
    "        #make a mapping between pixels and sparse (?)\n",
    "        fun = ImageD11.sinograms.lima_segmenter.frmtosparse( mask, np.uint16 )\n",
    "        npx, row, col, val = fun(frm, cut_value) #segment one image to check\n",
    "        ret = ImageD11.sinograms.lima_segmenter.top_pixels( npx, row, col, val, options.howmany,  options.thresholds)\n",
    "        spf = ImageD11.sinograms.lima_segmenter.clean( npx, row, col, val )\n",
    "\n",
    "        fig,ax = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "        ax[0].imshow(frm,norm=matplotlib.colors.LogNorm())\n",
    "        ax[1].imshow(spf.to_dense('intensity'),norm=matplotlib.colors.LogNorm())\n",
    "    if run_all:\n",
    "        ImageD11.sinograms.lima_segmenter.main(options,parallel=parallel)\n",
    "\n",
    "def merge_sparse(ds, outname=None):\n",
    "    if outname:\n",
    "        outname = os.path.join(ds.analysisroot,outname)\n",
    "    else:\n",
    "        outname=os.path.join(ds.analysisroot,ds.sample,f'{ds.sample}_{ds.dset}_sparse.h5')\n",
    "    outname=ImageD11.sinograms.assemble_label.harvest_masterfile(ds,outname)\n",
    "    return outname\n",
    "    \n",
    "def label_pixels(ds_file,sparse_file, pks_file=None):\n",
    "    if not pks_file:\n",
    "        pks_file=ds_file.replace('ds_','pks_')\n",
    "    #ImageD11.sinograms.properties.main(ds_file,sparse_file,pks_file)\n",
    "    #process each layer separately\n",
    "    ds = ImageD11.sinograms.dataset.load(ds_file)\n",
    "    for row,scan in enumerate(ds.scans):\n",
    "        print(f'----- {scan} -----')\n",
    "        pkst = ImageD11.sinograms.properties.pks_table_from_scan(sparse_file,ds,row)\n",
    "        scan_file = pks_file.replace('.h5',f'_{scan}.h5')\n",
    "        pkst.save(scan_file)\n",
    "\n",
    "    return pks_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to segment all scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "ds_all=[]\n",
    "sparse_all = []\n",
    "for scan in scan_names:\n",
    "    print(f'******** {scan} *********')\n",
    "    # create dataset and save ds_***.h5 file\n",
    "    ds,outname=setup_ds(scan,dataroot,analysisroot,sample)\n",
    "    ds_all.append(os.path.join(ds.analysisroot,ds.sample,outname)) #needed for labeling \n",
    "    # make a background image\n",
    "    bkgim,maskim, frm = make_bg(ds)\n",
    "    # segment spots\n",
    "    segment_spots(ds,outname,bkgim,maskim,frm,\n",
    "                  cut_value=200,\n",
    "                  check_segmentation=False,\n",
    "                  run_all=True,\n",
    "                  parallel=False)\n",
    "    sparse = merge_sparse(ds)\n",
    "    sparse_all.append(sparse) #needed for labeling\n",
    "    print(f'Saved sparse representation in {sparse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to label the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (scan,dsf,sparsef) in zip(scan_names,ds_all,sparse_all):\n",
    "    print(f'******** {scan} *********')\n",
    "    label_pixels(dsf,sparsef)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(ds.omega).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
